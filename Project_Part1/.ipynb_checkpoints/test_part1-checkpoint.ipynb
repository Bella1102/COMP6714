{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {1:'President Trump was on his way to new New York in New York City.',\n",
    "             2:'New York Times mentioned an interesting story about Trump.',\n",
    "             3:'I think it would be great if I can travel to New York this summer to see Trump.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trump': {1: 1, 2: 1, 3: 1},\n",
       " 'New York': {1: 1, 3: 1},\n",
       " 'New York City': {1: 1},\n",
       " 'New York Times': {2: 1},\n",
       " 'this summer': {3: 1}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'President': {1: 1},\n",
       " 'way': {1: 1},\n",
       " 'new': {1: 1},\n",
       " 'New': {1: 2, 2: 1, 3: 1},\n",
       " 'York': {1: 2, 2: 1, 3: 1},\n",
       " 'City': {1: 1},\n",
       " 'Times': {2: 1},\n",
       " 'mentioned': {2: 1},\n",
       " 'interesting': {2: 1},\n",
       " 'story': {2: 1},\n",
       " 'think': {3: 1},\n",
       " 'great': {3: 1},\n",
       " 'travel': {3: 1},\n",
       " 'summer': {3: 1}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 index_documents(self, documents):\n",
    "\n",
    "entity = {}\n",
    "token = {}\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for id, document in documents.items():\n",
    "    nlp_texts = nlp(document)\n",
    "\n",
    "    entity_list = []\n",
    "    for i in nlp_texts.ents:\n",
    "        entity_list.append(i.text)\n",
    "    for ent in entity_list:\n",
    "        dicts = {}\n",
    "        dicts[id] = entity_list.count(ent)\n",
    "        if ent not in entity.keys():\n",
    "            entity[ent] = dicts\n",
    "        else:\n",
    "            entity[ent][id] = dicts[id]\n",
    "\n",
    "    token_list = []\n",
    "    for i in nlp_texts:\n",
    "        if i.is_stop == False and i.is_punct == False:\n",
    "            token_list.append(i.text)\n",
    "    # 一个单词既是entity也是token：去掉token中此单词在entity中出现的次数\n",
    "    for i in entity_list:\n",
    "        if i in token_list:\n",
    "            token_list.remove(i)\n",
    "    for tok in  token_list:\n",
    "        dicts = {}\n",
    "        dicts[id] =  token_list.count(tok)\n",
    "        if tok not in token.keys():\n",
    "            token[tok] = dicts\n",
    "        else:\n",
    "            token[tok][id] = dicts[id]\n",
    "\n",
    "\n",
    "entity\n",
    "len(entity)\n",
    "token\n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 'New York Times Trump travel'\n",
    "DoE = {'New York Times':0, 'New York':1,'New York City':2}\n",
    "doc_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'York'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Times'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'New'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'York'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[{'tokens': ['New', 'York', 'Times', 'Trump', 'travel'], 'entities': []},\n",
       " {'tokens': ['Trump', 'travel'], 'entities': ['New York Times']},\n",
       " {'tokens': ['Times', 'Trump', 'travel'], 'entities': ['New York']}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2  split_query(self, Q, DoE):\n",
    "querys = []\n",
    "useful_entity = []\n",
    "subsets = [[]]\n",
    "valid_subsets = []\n",
    "\n",
    "for ent, ent_id in DoE.items():\n",
    "    if ent in Q:\n",
    "        useful_entity.append(ent)\n",
    "\n",
    "# 求子集\n",
    "for i in range(len(useful_entity)):\n",
    "    for j in range(len(subsets)):\n",
    "        subsets.append(subsets[j] + [useful_entity[i]])\n",
    "\n",
    "for subset in subsets:\n",
    "    tempQ = Q\n",
    "    is_contain = True\n",
    "    for item in subset:\n",
    "        if item in tempQ:\n",
    "            tempQ = tempQ.replace(item, \"\", 1)\n",
    "        else:\n",
    "            is_contain = False\n",
    "            break\n",
    "    if is_contain:\n",
    "        valid_subsets.append(subset)\n",
    "\n",
    "for subset in valid_subsets:\n",
    "    split_Q = Q.split()\n",
    "    for item in subset:\n",
    "        tempQ = item.split()\n",
    "        for k in tempQ:\n",
    "            index = split_Q.index(k)\n",
    "            # 有多余的返回数据            \n",
    "            split_Q.pop(index)\n",
    "    querys.append({'tokens': split_Q, 'entities': subset})\n",
    "\n",
    "querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.562186043243266: {'tokens': ['Times', 'Trump', 'travel'],\n",
       "  'entities': ['New York']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 max_score_query(self, query_splits, doc_id):\n",
    "\n",
    "document = documents[doc_id]\n",
    "score_list = []\n",
    "result = {}\n",
    "\n",
    "for query in querys:\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    entities = query['entities']\n",
    "    tokens = query['tokens']\n",
    "\n",
    "    if len(entities) == 0:\n",
    "        score1 = 0\n",
    "    else:\n",
    "        for ent in entities:\n",
    "            if ent in entity.keys() and doc_id in entity[ent].keys():\n",
    "                tf_entities = 1 + math.log(entity[ent][doc_id])\n",
    "                idf_entities = 1 + math.log(len(documents) / (len(entity[ent]) + 1))\n",
    "                score1 += tf_entities * idf_entities\n",
    "\n",
    "    for tok in tokens:\n",
    "        if tok in token.keys() and doc_id in token[tok].keys():\n",
    "            tf_tokens = 1 + math.log(1 + math.log(token[tok][doc_id]))\n",
    "            idf_tokens = 1 + math.log(len(documents) / (len(token[tok]) + 1))\n",
    "            score2 += tf_tokens * idf_tokens\n",
    "\n",
    "    score = score1 + 0.4 * score2\n",
    "    score_list.append([score1, score2, score, query])\n",
    "\n",
    "sort_score = sorted(score_list, key=lambda x: x[2], reverse=True)\n",
    "result[sort_score[0][2]] = sort_score[0][3]\n",
    "\n",
    "\n",
    "# score_list\n",
    "# sort_score \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
