{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import project_part1 as project_part1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {1: 'According to Times of India, President Donald Trump was on his way to New York City after his address at UNGA.',\n",
    "             2: 'The New York Times mentioned an interesting story about Trump.',\n",
    "             3: 'I think it would be great if I can travel to New York this summer to see Trump.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = project_part1.InvertedIndex()\n",
    "index.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'According': {1: 1},\n",
       "             'Times': {1: 1, 2: 1},\n",
       "             'India': {1: 1},\n",
       "             'President': {1: 1},\n",
       "             'Donald': {1: 1},\n",
       "             'Trump': {1: 1},\n",
       "             'way': {1: 1},\n",
       "             'New': {1: 1, 2: 1, 3: 1},\n",
       "             'York': {1: 1, 2: 1, 3: 1},\n",
       "             'City': {1: 1},\n",
       "             'address': {1: 1},\n",
       "             'mentioned': {2: 1},\n",
       "             'interesting': {2: 1},\n",
       "             'story': {2: 1},\n",
       "             'think': {3: 1},\n",
       "             'great': {3: 1},\n",
       "             'travel': {3: 1},\n",
       "             'summer': {3: 1}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Times of India': {1: 1},\n",
       "             'Donald Trump': {1: 1},\n",
       "             'New York City': {1: 1},\n",
       "             'UNGA': {1: 1},\n",
       "             'The New York Times': {2: 1},\n",
       "             'Trump': {2: 1, 3: 1},\n",
       "             'New York': {3: 1},\n",
       "             'this summer': {3: 1}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible query splits:\n",
      "\n",
      "{'tokens': ['The', 'New', 'New', 'York', 'City', 'Times', 'of', 'India'], 'entities': []}\n",
      "{'tokens': ['The', 'New', 'Times', 'of', 'India'], 'entities': ['New York City']}\n",
      "{'tokens': ['New', 'City', 'of', 'India'], 'entities': ['The New York Times']}\n",
      "{'tokens': ['The', 'New', 'New', 'York', 'City'], 'entities': ['Times of India']}\n",
      "{'tokens': ['The', 'New'], 'entities': ['New York City', 'Times of India']}\n"
     ]
    }
   ],
   "source": [
    "Q = 'The New New York City Times of India'\n",
    "DoE = {'Times of India':0, 'The New York Times':1,'New York City':2}\n",
    "\n",
    "query_splits = index.split_query(Q, DoE)\n",
    "\n",
    "print('Possible query splits:\\n')\n",
    "for key,split in query_splits.items():\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for each query split:\n",
      "\n",
      "query =  {'tokens': ['The', 'New', 'New', 'York', 'City', 'Times', 'of', 'India'], 'entities': []}\n",
      "{'tokens_score': 5.947883998860986, 'entities_score': 0.0, 'combined_score': 2.3791535995443946}\n",
      "\n",
      "query =  {'tokens': ['The', 'New', 'Times', 'of', 'India'], 'entities': ['New York City']}\n",
      "{'tokens_score': 3.117783035656384, 'entities_score': 1.4054651081081644, 'combined_score': 2.652578322370718}\n",
      "\n",
      "query =  {'tokens': ['New', 'City', 'of', 'India'], 'entities': ['The New York Times']}\n",
      "{'tokens_score': 3.5232481437645475, 'entities_score': 0.0, 'combined_score': 1.4092992575058192}\n",
      "\n",
      "query =  {'tokens': ['The', 'New', 'New', 'York', 'City'], 'entities': ['Times of India']}\n",
      "{'tokens_score': 3.5424188907528213, 'entities_score': 1.4054651081081644, 'combined_score': 2.822432664409293}\n",
      "\n",
      "query =  {'tokens': ['The', 'New'], 'entities': ['New York City', 'Times of India']}\n",
      "{'tokens_score': 0.7123179275482191, 'entities_score': 2.8109302162163288, 'combined_score': 3.0958573872356165}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1\n",
    "\n",
    "print('Score for each query split:\\n')\n",
    "result = index.max_score_query(query_splits, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.0958573872356165,\n",
       " {'tokens': ['The', 'New'], 'entities': ['New York City', 'Times of India']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The maximum score:')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {1: 'According to Los Angeles Times, The Boston Globe will be experiencing another recession in 2020. However, The Boston Globe decales it a hoax.',\n",
    "             2: 'The Washington Post declines the shares of George Washington.',\n",
    "             3: 'According to Los Angeles Times, the UNSW COMP6714 students should be able to finish project part-1 now.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = project_part1.InvertedIndex()\n",
    "index.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'According': {1: 1, 3: 1},\n",
       "             'Los': {1: 1, 3: 1},\n",
       "             'Angeles': {1: 1, 3: 1},\n",
       "             'Times': {1: 1, 3: 1},\n",
       "             'Boston': {1: 2},\n",
       "             'Globe': {1: 2},\n",
       "             'experiencing': {1: 1},\n",
       "             'recession': {1: 1},\n",
       "             'decales': {1: 1},\n",
       "             'hoax': {1: 1},\n",
       "             'Washington': {2: 2},\n",
       "             'Post': {2: 1},\n",
       "             'declines': {2: 1},\n",
       "             'shares': {2: 1},\n",
       "             'George': {2: 1},\n",
       "             'COMP6714': {3: 1},\n",
       "             'students': {3: 1},\n",
       "             'able': {3: 1},\n",
       "             'finish': {3: 1},\n",
       "             'project': {3: 1},\n",
       "             'part-1': {3: 1}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Los Angeles Times': {1: 1, 3: 1},\n",
       "             'The Boston Globe': {1: 2},\n",
       "             '2020': {1: 1},\n",
       "             'Washington Post': {2: 1},\n",
       "             'George Washington': {2: 1},\n",
       "             'UNSW': {3: 1}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.tf_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible query splits:\n",
      "\n",
      "{'tokens': ['Los', 'The', 'Angeles', 'Boston', 'Times', 'Globe', 'Washington', 'Post'], 'entities': []}\n",
      "{'tokens': ['The', 'Boston', 'Globe', 'Washington', 'Post'], 'entities': ['Los Angeles Times']}\n",
      "{'tokens': ['Los', 'Angeles', 'Times', 'Washington', 'Post'], 'entities': ['The Boston Globe']}\n",
      "{'tokens': ['Los', 'Angeles', 'Boston', 'Times', 'Globe'], 'entities': ['The Washington Post']}\n",
      "{'tokens': ['Washington', 'Post'], 'entities': ['Los Angeles Times', 'The Boston Globe']}\n",
      "{'tokens': ['Boston', 'Globe'], 'entities': ['Los Angeles Times', 'The Washington Post']}\n"
     ]
    }
   ],
   "source": [
    "Q = 'Los The Angeles Boston Times Globe Washington Post'\n",
    "DoE = {'Los Angeles Times':0, 'The Boston Globe':1,'The Washington Post':2, 'Star Tribune':3}\n",
    "\n",
    "query_splits = index.split_query(Q, DoE)\n",
    "\n",
    "print('Possible query splits:\\n')\n",
    "for key,split in query_splits.items():\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for each query split:\n",
      "\n",
      "query =  {'tokens': ['Los', 'The', 'Angeles', 'Boston', 'Times', 'Globe', 'Washington', 'Post'], 'entities': []}\n",
      "{'tokens_score': 7.29113524380594, 'entities_score': 0.0, 'combined_score': 2.916454097522376}\n",
      "\n",
      "query =  {'tokens': ['The', 'Boston', 'Globe', 'Washington', 'Post'], 'entities': ['Los Angeles Times']}\n",
      "{'tokens_score': 4.2911352438059405, 'entities_score': 1.0, 'combined_score': 2.7164540975223765}\n",
      "\n",
      "query =  {'tokens': ['Los', 'Angeles', 'Times', 'Washington', 'Post'], 'entities': ['The Boston Globe']}\n",
      "{'tokens_score': 3.0, 'entities_score': 2.3796592851687173, 'combined_score': 3.5796592851687175}\n",
      "\n",
      "query =  {'tokens': ['Los', 'Angeles', 'Boston', 'Times', 'Globe'], 'entities': ['The Washington Post']}\n",
      "{'tokens_score': 7.29113524380594, 'entities_score': 0.0, 'combined_score': 2.916454097522376}\n",
      "\n",
      "query =  {'tokens': ['Washington', 'Post'], 'entities': ['Los Angeles Times', 'The Boston Globe']}\n",
      "{'tokens_score': 0.0, 'entities_score': 3.3796592851687173, 'combined_score': 3.3796592851687173}\n",
      "\n",
      "query =  {'tokens': ['Boston', 'Globe'], 'entities': ['Los Angeles Times', 'The Washington Post']}\n",
      "{'tokens_score': 4.2911352438059405, 'entities_score': 1.0, 'combined_score': 2.7164540975223765}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1\n",
    "\n",
    "print('Score for each query split:\\n')\n",
    "result = index.max_score_query(query_splits, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum score:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.5796592851687175,\n",
       " {'tokens': ['Los', 'Angeles', 'Times', 'Washington', 'Post'],\n",
       "  'entities': ['The Boston Globe']})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The maximum score:\\n')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
